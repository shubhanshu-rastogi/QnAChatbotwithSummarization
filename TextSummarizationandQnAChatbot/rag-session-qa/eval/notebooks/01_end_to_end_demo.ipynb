{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End-to-End DeepEval (Single Question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "34a3cf38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "# If needed, uncomment to install/upgrade DeepEval\n",
        "!pip install -U deepeval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3a2b531d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backend: http://localhost:8000\n",
            "File: /Users/shubhanshurastogi_1/Learning/FinancialAssistant/rag-session-qa/eval/sample_docs/Match_Summary.pdf\n",
            "Publish to Confident AI: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('./../.env')\n",
        "\n",
        "ROOT = Path('..').resolve().parent\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "BASE_URL = os.getenv('BASE_URL', 'http://localhost:8000')\n",
        "FILE_PATH = Path(os.getenv('SAMPLE_FILE', '../sample_docs/Match_Summary.pdf')).resolve()\n",
        "PUBLISH = os.getenv('DEEPEVAL_PUBLISH', 'false').lower() == 'true'\n",
        "\n",
        "print('Backend:', BASE_URL)\n",
        "print('File:', FILE_PATH)\n",
        "print('Publish to Confident AI:', PUBLISH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c91871c8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "ROOT = Path('..').resolve().parent  # repo root\n",
        "load_dotenv(ROOT / 'backend' / '.env')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb410ba0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "from deepeval.evaluate import evaluate, AsyncConfig\n",
        "from deepeval.metrics import (\n",
        "    ContextualPrecisionMetric,\n",
        "    ContextualRecallMetric,\n",
        "    AnswerRelevancyMetric,\n",
        "    FaithfulnessMetric,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import ContextualRelevancyMetric\n",
        "except Exception:\n",
        "    ContextualRelevancyMetric = None\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import CompletenessMetric\n",
        "except Exception:\n",
        "    CompletenessMetric = None\n",
        "\n",
        "try:\n",
        "    from deepeval.metrics import GEval\n",
        "except Exception:\n",
        "    GEval = None\n",
        "\n",
        "def build_metrics():\n",
        "    metrics = [\n",
        "        ContextualPrecisionMetric(),\n",
        "        ContextualRecallMetric(),\n",
        "        AnswerRelevancyMetric(),\n",
        "        FaithfulnessMetric(),\n",
        "    ]\n",
        "    if ContextualRelevancyMetric is not None:\n",
        "        metrics.append(ContextualRelevancyMetric())\n",
        "    elif GEval is not None:\n",
        "        metrics.append(\n",
        "            GEval(\n",
        "                name='Context Relevance',\n",
        "                criteria='Evaluate how relevant the retrieval context is to the question. Score 0 to 1.',\n",
        "                evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.RETRIEVAL_CONTEXT],\n",
        "            )\n",
        "        )\n",
        "    if CompletenessMetric is not None:\n",
        "        metrics.append(CompletenessMetric())\n",
        "    elif GEval is not None:\n",
        "        metrics.append(\n",
        "            GEval(\n",
        "                name='Completeness',\n",
        "                criteria='Assess if the answer is complete given the context. Score 0 to 1.',\n",
        "                evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.RETRIEVAL_CONTEXT],\n",
        "            )\n",
        "        )\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cfe3cb",
      "metadata": {},
      "source": [
        "## Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3efd6cba",
      "metadata": {},
      "outputs": [],
      "source": [
        "QUESTION = 'How many sixes did Tilak Varma hit?'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82761c8a",
      "metadata": {},
      "source": [
        "## Upload Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cd4a520f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session: 185f2ade-c73f-43b6-a499-bc1dca64c466\n"
          ]
        }
      ],
      "source": [
        "with open(FILE_PATH, 'rb') as f:\n",
        "    files = {'file': (FILE_PATH.name, f)}\n",
        "    upload_res = requests.post(f'{BASE_URL}/upload', files=files)\n",
        "\n",
        "upload_res.raise_for_status()\n",
        "session_id = upload_res.json().get('session_id')\n",
        "print('Session:', session_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dba6edb",
      "metadata": {},
      "source": [
        "## Ask + Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7bf20114",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Tilak Varma hit 3 sixes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Completeness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4.1</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCompleteness \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4.1\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc58f5f27c2947aea246435038ab5a65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "\n",
            "Metrics Summary\n",
            "\n",
            "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the top-ranked node in the retrieval contexts directly states 'Tilak Varma hit 3 sixes', perfectly matching the input question. All relevant information is ranked at the top, with no irrelevant nodes present. Great job!, error: None)\n",
            "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the node(s) in retrieval context directly confirm that Tilak Varma hit 3 sixes, perfectly supporting the expected output., error: None)\n",
            "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because the answer was fully relevant and directly addressed the question without any irrelevant information. Great job staying focused and concise!, error: None)\n",
            "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 1.00 because there are no contradictions‚Äîthe actual output aligns perfectly with the retrieval context. Great job staying faithful to the source!, error: None)\n",
            "  - ‚ùå Contextual Relevancy (score: 0.25, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The score is 0.25 because only one statement, 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]', is relevant and directly answers the input, while the rest of the context is about other players or unrelated events., error: None)\n",
            "  - ‚úÖ Completeness [GEval] (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4.1, reason: The response correctly states that Tilak Varma hit 3 sixes, which is directly supported by the retrieval context '[4s-3 6s-3]'. The answer is complete and fully aligns with the information provided., error: None)\n",
            "\n",
            "For test case:\n",
            "\n",
            "  - input: How many sixes did Tilak Varma hit?\n",
            "  - actual output: Tilak Varma hit 3 sixes.\n",
            "  - expected output: Tilak Varma hit 3 sixes.\n",
            "  - context: None\n",
            "  - retrieval context: [\"aren't in use today so it took some time for everyone to realise what happened. A yorker from round the wicket, looks to flick it away, misses and it clips leg stump on the way. Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3] 10.5 4 Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it's swatted wide of mid-on. Fielder gets a hand diving across but it still runs away 10.2 Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it 10.1 4 Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\"]\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Overall Metric Pass Rates\n",
            "\n",
            "Contextual Precision: 100.00% pass rate\n",
            "Contextual Recall: 100.00% pass rate\n",
            "Answer Relevancy: 100.00% pass rate\n",
            "Faithfulness: 100.00% pass rate\n",
            "Contextual Relevancy: 0.00% pass rate\n",
            "Completeness [GEval]: 100.00% pass rate\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">‚ö† WARNING:</span> No hyperparameters logged.\n",
              "¬ª <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1;33m‚ö† WARNING:\u001b[0m No hyperparameters logged.\n",
              "¬ª \u001b]8;id=57800;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
              "\n",
              "================================================================================\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.</span>44s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.024382</span> USD<span style=\"font-weight: bold\">)</span>\n",
              "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
              "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
              "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
              "\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\n",
              "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m39.\u001b[0m44s | token cost: \u001b[1;36m0.024382\u001b[0m USD\u001b[1m)\u001b[0m\n",
              "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
              "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
              "\n",
              " ================================================================================ \n",
              "\n",
              "¬ª Want to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
              "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "EvaluationResult(test_results=[TestResult(name='test_case_0', success=False, metrics_data=[MetricData(name='Contextual Precision', threshold=0.5, success=True, score=1.0, reason=\"The score is 1.00 because the top-ranked node in the retrieval contexts directly states 'Tilak Varma hit 3 sixes', perfectly matching the input question. All relevant information is ranked at the top, with no irrelevant nodes present. Great job!\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.003576, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context contains the line \\'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\\', which directly states that Tilak Varma hit 3 sixes, matching the expected output.\"\\n    }\\n]'), MetricData(name='Contextual Recall', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the node(s) in retrieval context directly confirm that Tilak Varma hit 3 sixes, perfectly supporting the expected output.', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0029639999999999996, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The 1st node states: \\'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\\', which indicates Tilak Varma hit 3 sixes.\",\\n        \"expected_output\": \"Tilak Varma hit 3 sixes.\"\\n    }\\n]'), MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the answer was fully relevant and directly addressed the question without any irrelevant information. Great job staying focused and concise!', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.0028859999999999997, verbose_logs='Statements:\\n[\\n    \"Tilak Varma hit 3 sixes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Faithfulness', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because there are no contradictions‚Äîthe actual output aligns perfectly with the retrieval context. Great job staying faithful to the source!', strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.006776, verbose_logs='Truths (limit=None):\\n[\\n    \"A yorker from round the wicket clipped leg stump after the batter missed while trying to flick it away.\",\\n    \"Tilak Varma was bowled by Marco Jansen after scoring 45 runs off 19 balls, including 3 fours and 3 sixes.\",\\n    \"On the 10.5th ball, Marco Jansen bowled round the wicket, short of length across off, and Tilak Varma hit a four wide of mid-on despite a fielder\\'s diving effort.\",\\n    \"On the 10.2nd ball, Marco Jansen bowled to Suryakumar Yadav, who was dropped at deep midwicket by Bosch after toe-ending a scoop shot.\",\\n    \"On the 10.1st ball, Marco Jansen bowled a good length ball across off to Suryakumar Yadav, who hit a four via an inside edge past the stumps.\"\\n] \\n \\nClaims:\\n[\\n    \"Tilak Varma hit 3 sixes.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Contextual Relevancy', threshold=0.5, success=False, score=0.25, reason=\"The score is 0.25 because only one statement, 'Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]', is relevant and directly answers the input, while the rest of the context is about other players or unrelated events.\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.005625999999999999, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3]\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it\\'s swatted wide of mid-on. Fielder gets a hand diving across but it still runs away\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement describes a specific ball and shot but does not mention the number of sixes Tilak Varma hit.\"\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement is about Suryakumar Yadav and does not mention Tilak Varma or the number of sixes he hit.\"\\n            },\\n            {\\n                \"statement\": \"Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\",\\n                \"verdict\": \"no\",\\n                \"reason\": \"This statement is about Suryakumar Yadav and does not mention Tilak Varma or the number of sixes he hit.\"\\n            }\\n        ]\\n    }\\n]'), MetricData(name='Completeness [GEval]', threshold=0.5, success=True, score=1.0, reason=\"The response correctly states that Tilak Varma hit 3 sixes, which is directly supported by the retrieval context '[4s-3 6s-3]'. The answer is complete and fully aligns with the information provided.\", strict_mode=False, evaluation_model='gpt-4.1', error=None, evaluation_cost=0.002554, verbose_logs='Criteria:\\nAssess if the answer is complete given the context. Score 0 to 1. \\n \\nEvaluation Steps:\\n[\\n    \"Read the Input to understand the question or request.\",\\n    \"Review the Retrieval Context to identify all relevant information provided.\",\\n    \"Compare the Actual Output to the Input and Retrieval Context to determine if the answer addresses all aspects of the Input using the available context.\",\\n    \"Decide if the Actual Output is complete, missing, or partially missing information based on the Retrieval Context.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 1.0')], conversational=False, multimodal=False, input='How many sixes did Tilak Varma hit?', actual_output='Tilak Varma hit 3 sixes.', expected_output='Tilak Varma hit 3 sixes.', context=None, retrieval_context=[\"aren't in use today so it took some time for everyone to realise what happened. A yorker from round the wicket, looks to flick it away, misses and it clips leg stump on the way. Tilak Varma b Marco Jansen 45(19) [4s-3 6s-3] 10.5 4 Marco Jansen to Tilak Varma, FOUR, round the wicket, short of length across off, and it's swatted wide of mid-on. Fielder gets a hand diving across but it still runs away 10.2 Marco Jansen to Suryakumar Yadav, 1 run, dropped! Suryakumar having all the luck out there! Length ball on leg, tries his trademark scoop but is through the shot early. Toe-ends it in the air to deep midwicket and Bosch makes a meal of it 10.1 4 Marco Jansen to Suryakumar Yadav, FOUR, another inside edge past the stumps! Good length across off, he looks to loft down the ground but the\"], turns=None, additional_metadata=None)], confident_link=None, test_run_id=None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "payload = {'session_id': session_id, 'question': QUESTION}\n",
        "ask_res = requests.post(f'{BASE_URL}/ask', json=payload)\n",
        "ask_res.raise_for_status()\n",
        "ask_data = ask_res.json()\n",
        "answer = ask_data.get('answer', '')\n",
        "retrieval_context = ask_data.get('retrieval_context', [])\n",
        "print('Answer:', answer)\n",
        "\n",
        "test_case = LLMTestCase(\n",
        "    input=QUESTION,\n",
        "    actual_output=answer,\n",
        "    expected_output=answer,\n",
        "    retrieval_context=retrieval_context,\n",
        ")\n",
        "\n",
        "metrics = build_metrics()\n",
        "evaluate(\n",
        "    test_cases=[test_case],\n",
        "    metrics=metrics,\n",
        "    async_config=AsyncConfig(run_async=False)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metric Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec45720ad22544a3acfaf5fe094c2a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3d34055f18d4b0bb3d4e54149dce1a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8abee8514f0745e29381bb5580baefba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f23f9cbfc398410d8e969addf1ab887e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d298087ea8e4bf6a0aa1d73d7a40f40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8bb73459abe4219b7eb09ac7741e585",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>score</th>\n",
              "      <th>reason</th>\n",
              "      <th>success</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ContextualPrecisionMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the first node in th...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ContextualRecallMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the node(s) in retri...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AnswerRelevancyMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because the answer was fully...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FaithfulnessMetric</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The score is 1.00 because there are no contrad...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ContextualRelevancyMetric</td>\n",
              "      <td>0.25</td>\n",
              "      <td>The score is 0.25 because only one statement, ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Completeness</td>\n",
              "      <td>1.00</td>\n",
              "      <td>The Actual Output correctly states that Tilak ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      metric  score  \\\n",
              "0  ContextualPrecisionMetric   1.00   \n",
              "1     ContextualRecallMetric   1.00   \n",
              "2      AnswerRelevancyMetric   1.00   \n",
              "3         FaithfulnessMetric   1.00   \n",
              "4  ContextualRelevancyMetric   0.25   \n",
              "5               Completeness   1.00   \n",
              "\n",
              "                                              reason  success  \n",
              "0  The score is 1.00 because the first node in th...     True  \n",
              "1  The score is 1.00 because the node(s) in retri...     True  \n",
              "2  The score is 1.00 because the answer was fully...     True  \n",
              "3  The score is 1.00 because there are no contrad...     True  \n",
              "4  The score is 0.25 because only one statement, ...    False  \n",
              "5  The Actual Output correctly states that Tilak ...     True  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_rows = []\n",
        "for metric in build_metrics():\n",
        "    metric.measure(test_case)\n",
        "    score_rows.append({\n",
        "        'metric': getattr(metric, 'name', metric.__class__.__name__),\n",
        "        'score': getattr(metric, 'score', None),\n",
        "        'reason': getattr(metric, 'reason', None),\n",
        "        'success': getattr(metric, 'success', None),\n",
        "    })\n",
        "pd.DataFrame(score_rows)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
